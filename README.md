![Olist Data Science Project Cover](assets/images/cover_image.png)

ğŸ›ï¸ AnÃ¡lisis de SatisfacciÃ³n de Clientes â€“ Olist Marketplace

## ğŸ“„ DescripciÃ³n del Proyecto
Este proyecto analiza el comportamiento de los clientes y las entregas en el marketplace **Olist**, con el objetivo de identificar los factores que mÃ¡s influyen en la **satisfacciÃ³n del cliente** y el cumplimiento de entregas.  

El anÃ¡lisis incluye:  
- ğŸ“Š **AnÃ¡lisis Exploratorio de Datos (EDA)**  
- ğŸšš **EvaluaciÃ³n de tiempos de entrega y retrasos**  
- ğŸ’¬ **AnÃ¡lisis de satisfacciÃ³n del cliente (reviews y puntuaciones)**  
- ğŸ§  **Modelos de Machine Learning supervisados**  
  - RegresiÃ³n LogÃ­stica  
  - Random Forest  
  - XGBoost  
- ğŸ” **Interpretabilidad del modelo** con tÃ©cnicas de *Feature Importance* y *SHAP Values*  
- ğŸŒ **Visualizaciones geogrÃ¡ficas** con mapas interactivos (Folium / Plotly)
- ğŸ—ºï¸ **Enriquecimiento geogrÃ¡fico** con Google Maps API para cÃ¡lculo de distancias estado-estado
- ğŸ’­ **AnÃ¡lisis de sentimiento (NLP)** utilizando modelos de HuggingFace para procesar reseÃ±as en portuguÃ©s
- ğŸ“ˆ **Re-entrenamiento de modelos** con variables enriquecidas (geogrÃ¡ficas + sentimiento)

---

## ğŸ§© Estructura del Notebook
1. **Carga de datos** desde archivos CSV y creaciÃ³n de base SQLite.  
2. **IntegraciÃ³n de tablas** (Ã³rdenes, clientes, productos, envÃ­os, reseÃ±as).  
3. **Data Wrangling y limpieza de valores nulos.**  
4. **EDA:** anÃ¡lisis univariado, bivariado y multivariado (PCA y MANOVA).  
5. **Modelado predictivo:** entrenamiento, optimizaciÃ³n y evaluaciÃ³n comparativa de modelos.  
6. **Enriquecimiento geogrÃ¡fico con Google Maps API:** cÃ¡lculo de distancias y tiempos estimados entre estados (seller-customer) para anÃ¡lisis logÃ­stico regional.  
7. **AnÃ¡lisis de sentimiento (NLP):** procesamiento de reseÃ±as con modelos de HuggingFace, generaciÃ³n de variables de polaridad emocional y visualizaciÃ³n mediante nubes de palabras.  
8. **IntegraciÃ³n de variables enriquecidas:** merge de distancias geogrÃ¡ficas y sentimientos al dataset principal (`df_vista_base`) y EDA multivariable del dataset enriquecido.  
9. **Re-entrenamiento del modelo:** evaluaciÃ³n comparativa del modelo mejorado con variables externas (Google Maps + sentimiento) vs. modelo original.  

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas
- ğŸ **Python 3.9+**  
- ğŸ“¦ **Pandas / NumPy** â€“ ManipulaciÃ³n y anÃ¡lisis de datos  
- ğŸ“Š **Matplotlib / Seaborn / Plotly** â€“ Visualizaciones  
- ğŸ¤– **Scikit-learn / XGBoost** â€“ Modelos de Machine Learning  
- ğŸŒ **Folium / GeoPandas** â€“ Mapas interactivos y anÃ¡lisis espacial  
- ğŸ“ˆ **Statsmodels / SciPy** â€“ AnÃ¡lisis estadÃ­stico (ANOVA, MANOVA, correlaciones)  
- ğŸ” **SHAP** â€“ Interpretabilidad de modelos  
- ğŸ—„ï¸ **SQLite3** â€“ Base de datos relacional local  
- ğŸ—ºï¸ **Google Maps API** â€“ CÃ¡lculo de distancias y tiempos de viaje entre estados  
- ğŸ¤— **HuggingFace Transformers** â€“ Modelos de NLP para anÃ¡lisis de sentimiento multilingÃ¼e  
- â˜ï¸ **WordCloud** â€“ VisualizaciÃ³n de tÃ©rminos mÃ¡s frecuentes en reseÃ±as  

---

## ğŸ“ˆ PrÃ³ximos Pasos
- ğŸšš **Incorporar datos reales de transporte:** tiempos reales por transportista, velocidad media por ruta, capacidad de carga, e incidencias por clima o feriados.  
- ğŸ¤– **Modelos adicionales:** experimentar con LightGBM, CatBoost (excelente para datos categÃ³ricos) y redes neuronales ligeras (MLP).  
- ğŸ—ºï¸ **Profundizar anÃ¡lisis geogrÃ¡fico:** mapas de calor de retrasos por municipio y feature engineering con "densidad de pedidos por zona".  
- ğŸ’­ **AnÃ¡lisis de sentimiento ampliado:** implementar topic modeling (LDA o BERTopic) y clasificaciÃ³n de emociones (enojo, frustraciÃ³n, satisfacciÃ³n).  
- ğŸš€ **OptimizaciÃ³n y despliegue:** implementar pipelines automatizados para actualizaciÃ³n periÃ³dica de datos enriquecidos y despliegue en entorno reproducible.

---

## ğŸ“ Estructura del Proyecto

```

â”œâ”€â”€ assets/ # Recursos grÃ¡ficos y archivos de soporte (mapas, imÃ¡genes, etc.)
â”‚   â””â”€â”€ images/ # ImÃ¡genes del proyecto (cover, visualizaciones, etc.)
â”œâ”€â”€ inputs/ # Archivos CSV procesados para uso en las secciones 6-9
â”‚   â”œâ”€â”€ distancias_estados_google.csv # Distancias y tiempos entre estados (Google Maps API)
â”‚   â””â”€â”€ sentiment_reviews_olist.csv # ReseÃ±as con anÃ¡lisis de sentimiento (HuggingFace)
â”œâ”€â”€ .gitignore # Exclusiones de archivos para Git
â”œâ”€â”€ README.md # DescripciÃ³n y documentaciÃ³n general del proyecto
â”œâ”€â”€ olist_data_science_project.ipynb # Notebook principal con el anÃ¡lisis completo (EDA, PCA, ML, SHAP, enriquecimiento geogrÃ¡fico, NLP)
â””â”€â”€ olist_data_science_project.py # Script en Python con las funciones principales y ejecuciÃ³n modular

```


## ğŸš€ InstalaciÃ³n

```bash
# Clonar el repositorio
git clone https://github.com/vanerm/olist-data-science-project.git
cd olist-data-science-project

# Instalar dependencias
pip install -r requirements.txt
```

## ğŸ“Š Dataset

### Datasets Originales

> ğŸ’¡ *Nota:* Los datasets originales no se incluyen en el repositorio por tamaÃ±o y polÃ­ticas de privacidad.  
> Pueden descargarse desde el dataset pÃºblico de [Olist Kaggle Dataset](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce) disponible en Kaggle.

### Datasets Procesados (inputs/)

El proyecto incluye archivos CSV procesados en la carpeta `inputs/` que contienen datos enriquecidos utilizados en las secciones 6-9:

- **`distancias_estados_google.csv`** (43 KB): Contiene distancias y tiempos estimados entre estados calculados mediante Google Maps API. Incluye coordenadas de estados, distancias en kilÃ³metros y tiempos estimados en minutos.

- **`sentiment_reviews_olist.csv`** (6.7 MB): Contiene las reseÃ±as de clientes procesadas con anÃ¡lisis de sentimiento utilizando modelos de HuggingFace. Incluye variables como `sentiment_label_raw`, `sentiment_score_raw`, `sentiment_stars` y `sentiment_polarity`.

> âœ… **Estos archivos pueden subirse a GitHub** ya que son datos procesados/derivados del anÃ¡lisis y no contienen informaciÃ³n sensible. Sus tamaÃ±os estÃ¡n dentro de los lÃ­mites permitidos por GitHub (archivos < 100MB no requieren Git LFS).


## ğŸ”— ConexiÃ³n con Google Colab

Este repositorio estÃ¡ configurado para trabajar directamente con Google Colab.

**[ğŸš€ Abrir en Google Colab](https://colab.research.google.com/drive/1sBmDUGT13lOsoGc8JseWFglr7zCNDdNk?usp=sharing)**

## ğŸ“¦ ObtenciÃ³n de los datos desde Kaggle

Para ejecutar este proyecto es necesario descargar el dataset pÃºblico de **Olist Brazilian E-Commerce** desde Kaggle.  
A continuaciÃ³n se detallan los pasos para generar la **API key**, configurarla en **Google Colab** y descargar los archivos de forma automÃ¡tica.

---

### ğŸ”‘ Paso 1. Generar la API Key en Kaggle

1. IniciÃ¡ sesiÃ³n en tu cuenta de [Kaggle](https://www.kaggle.com/).  
2. HacÃ© clic en tu foto de perfil (esquina superior derecha) â†’ **Account**.  
3. Desplazate hasta la secciÃ³n **API**.  
4. HacÃ© clic en **Create New API Token**.  
5. Se descargarÃ¡ un archivo llamado **`kaggle.json`**, que contiene tus credenciales personales.

> âš ï¸ **Importante:** No compartas este archivo ni lo subas a repositorios pÃºblicos. Contiene tu clave privada de acceso a la API de Kaggle.

---

### ğŸ’¾ Paso 2. Subir la API Key a Google Colab

EjecutÃ¡ el siguiente bloque en tu notebook y seleccionÃ¡ el archivo `kaggle.json` descargado:

```python
from google.colab import files
files.upload()  # seleccionar el archivo kaggle.json desde tu computadora
```

### ğŸ“ Paso 3. Configurar la ruta para la CLI de Kaggle

Los siguientes comandos crean la carpeta correcta, mueven el archivo kaggle.json y le asignan permisos de lectura seguros:

```bash
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
```

### ğŸ“¥ Paso 4. Descargar y descomprimir el dataset de Olist

Una vez configurado el acceso, descargÃ¡ el dataset con los siguientes comandos:

```bash
!kaggle datasets download -d olistbr/brazilian-ecommerce -p /content
!unzip -o /content/brazilian-ecommerce.zip -d /content/olist_dataset
```

### ğŸ” Paso 5. Verificar los archivos descargados

Para confirmar que los CSV fueron descargados correctamente, listÃ¡ los primeros archivos del dataset:

```bash
!ls /content/olist_dataset | sed -n '1,20p'
```

VerÃ¡s archivos como:

- olist_orders_dataset.csv
- olist_customers_dataset.csv
- olist_order_items_dataset.csv
- olist_products_dataset.csv
- olist_sellers_dataset.csv, entre otros.

### âœ… Resultado esperado

Al finalizar estos pasos, tendrÃ¡s todos los archivos del dataset Olist Brazilian E-Commerce disponibles en tu entorno de trabajo (/content/olist_dataset), listos para ser utilizados en las siguientes etapas del anÃ¡lisis:

- ExploraciÃ³n y limpieza de datos (EDA)
- AnÃ¡lisis de comportamiento de clientes
- Modelado predictivo y evaluaciÃ³n de satisfacciÃ³n
- Enriquecimiento geogrÃ¡fico con Google Maps API
- AnÃ¡lisis de sentimiento mediante NLP (HuggingFace)
- IntegraciÃ³n de variables enriquecidas al dataset principal
- Re-entrenamiento y mejora de modelos predictivos
- Visualizaciones y dashboards interactivos


## ğŸ“ˆ Resultados Principales

- [Notebook interactivo en Kaggle â€“ AnÃ¡lisis de satisfacciÃ³n y logÃ­stica](https://www.kaggle.com/code/vanesamizrahi/olist-an-lisis-de-satisfacci-n-y-log-stica)
- [AnÃ¡lisis de satisfacciÃ³n y logÃ­stica del Marketplace Olist (presentaciÃ³n)](https://docs.google.com/presentation/d/1mDuVNark3nnoYhvbLiFD52rtzURoOvEXpSQduoCVmCA/edit?usp=sharing)

## ğŸ¤ ContribuciÃ³n

Este es un proyecto educativo desarrollado como parte del curso de Data Science II de la Diplomatura de Data Science en [Coder House](https://www.coderhouse.com/).

## ğŸ“„ Licencia

Este proyecto es de uso educativo.

## ğŸ‘‹ About Me

Â¡Hola! Soy **Vanesa Mizrahi**, desarrolladora mobile iOS y apasionada por los datos y el aprendizaje continuo.

### ğŸ”— Conecta conmigo
- **LinkedIn:** [Vanesa Mizrahi](https://www.linkedin.com/in/vanesamizrahi)

### ğŸ’¡ Sobre este proyecto

Este proyecto fue desarrollado como parte del curso **Data Science II** de la carrera de **Data Science** en **CoderHouse**,  
donde se aplicaron tÃ©cnicas avanzadas de anÃ¡lisis de datos, estadÃ­stica multivariada y machine learning.  

El trabajo integra todas las etapas del proceso de ciencia de datos:
- ExtracciÃ³n y limpieza de datos desde fuentes pÃºblicas.  
- AnÃ¡lisis exploratorio (EDA) y visualizaciÃ³n interactiva.  
- FormulaciÃ³n y validaciÃ³n de hipÃ³tesis estadÃ­sticas.  
- ConstrucciÃ³n y evaluaciÃ³n de modelos supervisados.  
- Enriquecimiento de datos con APIs externas (Google Maps API para anÃ¡lisis geogrÃ¡fico).  
- Procesamiento de lenguaje natural (NLP) para anÃ¡lisis de sentimiento en reseÃ±as.  
- IntegraciÃ³n de mÃºltiples fuentes de datos (estructurados, geogrÃ¡ficos y textuales).  
- Mejora iterativa de modelos mediante incorporaciÃ³n de nuevas features enriquecidas.  
- InterpretaciÃ³n de resultados y conclusiones orientadas al negocio.  

El objetivo principal fue desarrollar una **soluciÃ³n analÃ­tica completa** basada en datos reales del marketplace **Olist**,  
capaz de explicar los factores que influyen en la **satisfacciÃ³n del cliente** y predecir comportamientos a partir de variables logÃ­sticas y de compra.

Â¡Gracias por revisar mi trabajo! ğŸš€

